{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport os\nimport sys\nimport glob\nimport torch\nimport torchvision\n\nimport numpy as np\nimport datetime as dt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom collections import Counter  # Add this import\nfrom torch.utils.data import Dataset\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms, datasets, models\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-27T19:06:46.654969Z","iopub.execute_input":"2023-08-27T19:06:46.655659Z","iopub.status.idle":"2023-08-27T19:06:46.885911Z","shell.execute_reply.started":"2023-08-27T19:06:46.655622Z","shell.execute_reply":"2023-08-27T19:06:46.885027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the device for training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:06:50.704895Z","iopub.execute_input":"2023-08-27T19:06:50.705284Z","iopub.status.idle":"2023-08-27T19:06:50.739628Z","shell.execute_reply.started":"2023-08-27T19:06:50.705250Z","shell.execute_reply":"2023-08-27T19:06:50.737252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install numpy==1.23.5\n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:06:51.644787Z","iopub.execute_input":"2023-08-27T19:06:51.645513Z","iopub.status.idle":"2023-08-27T19:06:51.652799Z","shell.execute_reply.started":"2023-08-27T19:06:51.645476Z","shell.execute_reply":"2023-08-27T19:06:51.649285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\n\n\n# Modify the data transformation for grayscale images\ntransforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.Grayscale(num_output_channels=3),  \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485], std=[0.229])  # Use single value for mean and std\n])\n\ntrain_dataset = ImageFolder('/kaggle/input/brain-tumor-mri-dataset/Training', transform=transforms)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nval_dataset = ImageFolder('/kaggle/input/brain-tumor-mri-dataset/Testing', transform=transforms)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:06:52.194810Z","iopub.execute_input":"2023-08-27T19:06:52.195200Z","iopub.status.idle":"2023-08-27T19:06:57.678757Z","shell.execute_reply.started":"2023-08-27T19:06:52.195166Z","shell.execute_reply":"2023-08-27T19:06:57.677727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute class weights\ndef compute_class_weights(labels):\n    label_counts = Counter(labels)\n    class_weights = [1.0 / label_counts[label] for label in labels]\n    return torch.tensor(class_weights, dtype=torch.float)\n\nclass Tumor(Dataset):\n    def __init__(self, path, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, fileName])\n        self.file_list = files\n\n        # Compute class weights\n        labels = [item[0] for item in self.file_list]\n        self.class_weights = compute_class_weights(labels)\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][1]\n        classCategory = self.file_list[idx][0]\n        im = Image.open(fileName)\n\n        if self.transform:\n            im = self.transform(im)\n\n        return im, classCategory","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:06:57.680721Z","iopub.execute_input":"2023-08-27T19:06:57.681022Z","iopub.status.idle":"2023-08-27T19:06:57.692117Z","shell.execute_reply.started":"2023-08-27T19:06:57.680996Z","shell.execute_reply":"2023-08-27T19:06:57.691151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/brain-tumor-mri-dataset\"\ntrain_path = join(data_path, \"Training\")\ntest_path = join(data_path,\"Testing\")","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:06:57.693511Z","iopub.execute_input":"2023-08-27T19:06:57.694319Z","iopub.status.idle":"2023-08-27T19:06:57.707820Z","shell.execute_reply.started":"2023-08-27T19:06:57.694275Z","shell.execute_reply":"2023-08-27T19:06:57.706976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = Tumor(train_path, transform=transforms)\ntest_data = Tumor(test_path, transform=transforms)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:06:59.215939Z","iopub.execute_input":"2023-08-27T19:06:59.216871Z","iopub.status.idle":"2023-08-27T19:06:59.269427Z","shell.execute_reply.started":"2023-08-27T19:06:59.216837Z","shell.execute_reply":"2023-08-27T19:06:59.268545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# step 3\n# Load a batch of images and labels for visualization\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\n\n# Convert images to numpy arrays and denormalize\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nimages = (images.numpy().transpose((0, 2, 3, 1)) * std + mean).clip(0, 1)\n\n# Create a grid of images\nnum_images = len(images)\nrows = int(np.ceil(num_images / 4))\nfig, axes = plt.subplots(rows, 4, figsize=(15, 15))\n\n# Plot images with labels\nfor i, ax in enumerate(axes.flat):\n    if i < num_images:\n        ax.imshow(images[i])\n        ax.set_title(f'Label: {train_dataset.classes[labels[i]]}')\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:07:04.094977Z","iopub.execute_input":"2023-08-27T19:07:04.096170Z","iopub.status.idle":"2023-08-27T19:07:07.112351Z","shell.execute_reply.started":"2023-08-27T19:07:04.096124Z","shell.execute_reply":"2023-08-27T19:07:07.111147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nvalidation_split = 0.2\nrandom_seed = 42\nshuffle_dataset = True  # Define shuffle_dataset variable here\n\n# Creating data indices for training and validation splits\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset:\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:07:14.472854Z","iopub.execute_input":"2023-08-27T19:07:14.473249Z","iopub.status.idle":"2023-08-27T19:07:14.966836Z","shell.execute_reply.started":"2023-08-27T19:07:14.473215Z","shell.execute_reply":"2023-08-27T19:07:14.965848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=16","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:07:24.875149Z","iopub.execute_input":"2023-08-27T19:07:24.875843Z","iopub.status.idle":"2023-08-27T19:07:24.880404Z","shell.execute_reply.started":"2023-08-27T19:07:24.875806Z","shell.execute_reply":"2023-08-27T19:07:24.879368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import SubsetRandomSampler, DataLoader\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\nval_loader = DataLoader(train_data, batch_size=batch_size, sampler=val_sampler)\ntest_loader = DataLoader(test_data, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:07:27.584632Z","iopub.execute_input":"2023-08-27T19:07:27.584998Z","iopub.status.idle":"2023-08-27T19:07:27.591580Z","shell.execute_reply.started":"2023-08-27T19:07:27.584966Z","shell.execute_reply":"2023-08-27T19:07:27.590370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import resnet50\n# Step 4: Define the ResNet-50 based classifier\nclass TumorClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(TumorClassifier, self).__init__()\n        self.resnet50 = resnet50(pretrained=True)\n        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, num_classes)\n        \n    def forward(self, x):\n        return self.resnet50(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:13:51.737974Z","iopub.execute_input":"2023-08-25T09:13:51.738879Z","iopub.status.idle":"2023-08-25T09:13:51.745877Z","shell.execute_reply.started":"2023-08-25T09:13:51.738813Z","shell.execute_reply":"2023-08-25T09:13:51.744882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet-pytorch\n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:06:12.507287Z","iopub.execute_input":"2023-08-27T19:06:12.507654Z","iopub.status.idle":"2023-08-27T19:06:26.615992Z","shell.execute_reply.started":"2023-08-27T19:06:12.507627Z","shell.execute_reply":"2023-08-27T19:06:26.614861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n\n# Step 4: Define the EfficientNet-based classifier\nclass TumorClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(TumorClassifier, self).__init__()\n        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')  # You can choose different variants\n        num_ftrs = self.efficientnet._fc.in_features\n        self.efficientnet._fc = nn.Linear(num_ftrs, num_classes)\n        \n    def forward(self, x):\n        return self.efficientnet(x)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:07:34.046305Z","iopub.execute_input":"2023-08-27T19:07:34.046670Z","iopub.status.idle":"2023-08-27T19:07:34.053347Z","shell.execute_reply.started":"2023-08-27T19:07:34.046639Z","shell.execute_reply":"2023-08-27T19:07:34.052254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import densenet121\n\n# Step 4: Define the DenseNet-based classifier\nclass TumorClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(TumorClassifier, self).__init__()\n        self.densenet = densenet121(pretrained=True)\n        num_ftrs = self.densenet.classifier.in_features\n        self.densenet.classifier = nn.Linear(num_ftrs, num_classes)\n        \n    def forward(self, x):\n        return self.densenet(x)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:42:20.045784Z","iopub.execute_input":"2023-08-27T19:42:20.046219Z","iopub.status.idle":"2023-08-27T19:42:20.054298Z","shell.execute_reply.started":"2023-08-27T19:42:20.046181Z","shell.execute_reply":"2023-08-27T19:42:20.053131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n# Create the model, move it to the device, define loss function and optimizer\nmodel = TumorClassifier(num_classes=4)\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0002)\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-08-27T19:42:24.184093Z","iopub.execute_input":"2023-08-27T19:42:24.184535Z","iopub.status.idle":"2023-08-27T19:42:25.015001Z","shell.execute_reply.started":"2023-08-27T19:42:24.184503Z","shell.execute_reply":"2023-08-27T19:42:25.013970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:09:02.208983Z","iopub.execute_input":"2023-08-14T18:09:02.209347Z","iopub.status.idle":"2023-08-14T18:09:02.214450Z","shell.execute_reply.started":"2023-08-14T18:09:02.209317Z","shell.execute_reply":"2023-08-14T18:09:02.213212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef train(model, criterion, train_loader, val_loader, optimizer, num_epochs, patience):\n    \"\"\"Train a model with early stopping.\"\"\"\n   \n\n    # Exponential moving average of the loss.\n    ema_loss = None\n\n    # Variables for early stopping\n    best_loss = np.inf\n    epochs_without_improvement = 0\n\n    print('----- Training Loop -----')\n\n    # Loop over epochs.\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n\n        # Loop over training data.\n        for batch_idx, (features, target) in enumerate(train_loader):\n            # Move data to the device.\n            features = features.to(device)\n            target = target.to(device)\n\n            # Forward pass.\n            output = model(features)\n            loss = criterion(output, target)\n\n            # Backward pass.\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Update exponential moving average of the loss.\n            if ema_loss is None:\n                ema_loss = loss.item()\n            else:\n                ema_loss += (loss.item() - ema_loss) * 0.01\n\n        # Print training progress at the end of the epoch.\n        print('Epoch: {} \\tTraining Loss: {:.3f}'.format(epoch, ema_loss))\n\n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n\n        with torch.no_grad():\n            for val_data in val_loader:\n                val_inputs, val_labels = val_data\n                val_inputs = val_inputs.to(device)\n                val_labels = val_labels.to(device)\n\n                val_outputs = model(val_inputs)\n                loss = criterion(val_outputs, val_labels)\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        # Check if validation loss has improved\n        if val_loss < best_loss:\n            best_loss = val_loss\n            epochs_without_improvement = 0\n        else:\n            epochs_without_improvement += 1\n\n        \n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:42:34.164617Z","iopub.execute_input":"2023-08-27T19:42:34.165229Z","iopub.status.idle":"2023-08-27T19:42:34.177634Z","shell.execute_reply.started":"2023-08-27T19:42:34.165183Z","shell.execute_reply":"2023-08-27T19:42:34.176559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nnum_epochs = 20\npatience = 3\ntrain(model, criterion, train_loader, val_loader, optimizer, num_epochs, patience)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:42:36.855035Z","iopub.execute_input":"2023-08-27T19:42:36.855426Z","iopub.status.idle":"2023-08-27T20:01:25.659549Z","shell.execute_reply.started":"2023-08-27T19:42:36.855393Z","shell.execute_reply":"2023-08-27T20:01:25.658474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, data_loader):\n    \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n    # Make sure the model is in evaluation mode.\n    model.eval()\n    correct = 0\n    total = 0\n\n    print('----- Model Evaluation -----')\n    # We do not need to maintain intermediate activations while testing.\n    with torch.no_grad():\n        # Loop over test data.\n        for features, target in data_loader:\n            # Move data to the device.\n            features = features.to(device)\n            target = target.to(device)\n\n            # Forward pass.\n            output = model(features)\n\n            # Get the label corresponding to the highest predicted probability.\n            _, predicted = torch.max(output.data, 1)\n\n            # Count number of correct predictions.\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    # Calculate test accuracy.\n    accuracy = 100 * correct / total\n    print(f'Test accuracy: {correct} / {total} ({accuracy:.2f}%)')\n\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-08-27T20:21:32.193278Z","iopub.execute_input":"2023-08-27T20:21:32.193694Z","iopub.status.idle":"2023-08-27T20:21:32.203268Z","shell.execute_reply.started":"2023-08-27T20:21:32.193660Z","shell.execute_reply":"2023-08-27T20:21:32.202242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T20:21:43.528705Z","iopub.execute_input":"2023-08-27T20:21:43.529063Z","iopub.status.idle":"2023-08-27T20:21:51.425596Z","shell.execute_reply.started":"2023-08-27T20:21:43.529033Z","shell.execute_reply":"2023-08-27T20:21:51.424640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Make predictions on the test images\npredictions = []\ntest_image_fileNames = []\n\n# Loop over test data.\nfor image, label in test_loader:\n    # Move data to the device.\n    image = image.to(device)\n    \n    # Perform the prediction on the batch of images\n    with torch.no_grad():\n        output = model(image)\n        _, predicted = torch.max(output.data, 1)\n        \n    # Convert the predicted labels to class names\n    predicted_classes = [train_dataset.classes[p.item()] for p in predicted]\n    \n    # Append the predicted classes and image names to the lists\n    predictions.extend(predicted_classes)\n    test_image_fileNames.extend(label)\n\n# Print the predictions for each image\nfor image_name, prediction in zip(test_image_fileNames, predictions):\n    print(f\"Image: {image_name}, Predicted Class: {prediction}\")\n# Save the results to a text file\nwith open(\"predictions.txt\", \"w\") as f:\n    for image_name, prediction in results:\n        f.write(f\"Image: {image_name}, Predicted Class: {prediction}\\n\")\n\nprint(\"Predictions saved to predictions.txt\")","metadata":{"execution":{"iopub.status.busy":"2023-08-27T19:38:58.685462Z","iopub.execute_input":"2023-08-27T19:38:58.685880Z","iopub.status.idle":"2023-08-27T19:39:06.860996Z","shell.execute_reply.started":"2023-08-27T19:38:58.685843Z","shell.execute_reply":"2023-08-27T19:39:06.860086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}